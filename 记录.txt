
# 单卡看下是否能正常加载除模型外的东西
xtuner train projects/configs/rrr_internlm2_chat_7b_clip_vit_large_p14_336_e1_gpu8_pretrain.py --deepspeed deepspeed_zero2
xtuner train projects/configs/rrr_internlm2_chat_7b_clip_vit_large_p14_336_qlora_e1_gpu8_finetune_stage1.py --deepspeed deepspeed_zero2
srun -p s1_mm_dev python xtuner/tools/train.py projects/configs/rrr_internlm2_chat_7b_clip_vit_large_p14_336_qlora_e1_gpu8_finetune_stage1.py --deepspeed deepspeed_zero2

export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER=GNU
proxy_on 不然会卡住
NPROC_PER_NODE=8 srun -p s1_mm_dev --job-name=rrr_1 --cpus-per-task=16  --nodes=1 --gres=gpu:8 --ntasks-per-node=1 --kill-on-bad-exit=1  xtuner train projects/configs/rrr_internlm2_chat_7b_clip_vit_large_p14_336_e1_gpu8_pretrain.py --deepspeed deepspeed_zero2

/mnt/petrelfs/huanghaian/miniconda3/envs/xtuner-env/lib/python3.10/site-packages/deepspeed/__init__.py

L135:   dist.init_distributed(dist_backend=dist_backend, dist_init_required=dist_init_required, distributed_port=29501)


export PYTHONPATH="$(pwd)"
NPROC_PER_NODE=8 srun -p s1_mm_dev --job-name=rrr_2 --cpus-per-task=16  --nodes=1 --gres=gpu:8 --ntasks-per-node=1 --kill-on-bad-exit=1  xtuner train projects/configs/rrr_internlm2_chat_7b_clip_vit_large_p14_336_qlora_e1_gpu8_finetune_stage1.py --deepspeed deepspeed_zero2
